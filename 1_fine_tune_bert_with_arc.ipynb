{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ARC dataset\n",
    "arc_dataset = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', token=\"\")\n",
    "model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased', token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label.isdigit():  # Check if the label is a digit\n",
    "        return int(label) - 1\n",
    "    else:  # Assume the label is a letter (A, B, C, D)\n",
    "        return ord(label) - ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arc_function(examples):\n",
    "    # Unpack questions and choices\n",
    "    questions = examples[\"question\"]\n",
    "    choices = examples['choices']\n",
    "\n",
    "    # Prepare first and second sentences\n",
    "\n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "\n",
    "    # Prepare labels array if you need to handle labels dynamically as well\n",
    "    labels = []  \n",
    "\n",
    "    # Number of choices can vary\n",
    "    num_choices_per_question = []\n",
    "\n",
    "    for i, (question, choice_dict) in enumerate(zip(questions, choices)):\n",
    "        num_choices = len(choice_dict['text'])\n",
    "        num_choices_per_question.append(num_choices)\n",
    "        \n",
    "        # Repeat the question for each choice\n",
    "        first_sentences.extend([question] * num_choices)\n",
    "        \n",
    "        # Extend second sentences with each choice\n",
    "        second_sentences.extend(choice_dict['text'])\n",
    "\n",
    "        # If you're handling labels, adapt this part to your data structure\n",
    "        labels.append(convert_label(examples['answerKey'][i]))\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True, return_tensors='pt', padding=True)\n",
    "\n",
    "    # Un-flatten the tokenized outputs to maintain structure [number of examples, number of choices per example]\n",
    "    tokenized_outputs = {key: [] for key in tokenized_examples.keys()}\n",
    "    index = 0\n",
    "    for count in num_choices_per_question:\n",
    "        for key in tokenized_examples.keys():\n",
    "            tokenized_outputs[key].append(tokenized_examples[key][index:index + count])\n",
    "        index += count\n",
    "\n",
    "    # If using labels, make sure to format them here too\n",
    "    tokenized_outputs['labels'] = labels\n",
    "\n",
    "    return tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and prepare dataset\n",
    "#tokenized_arc = arc_dataset.map(lambda examples: preprocess_arc_function(examples, tokenizer), batched=True)\n",
    "tokenized_arc = arc_dataset.map(preprocess_arc_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_arc['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]  # Extract labels from features\n",
    "\n",
    "        flattened_features = []\n",
    "        num_choices_per_feature=[]\n",
    "        for feature in features:\n",
    "            # Determine the number of choices for the current question\n",
    "            num_choices = len(feature[\"input_ids\"])  # Assuming 'input_ids' represents the number of choices\n",
    "            num_choices_per_feature.append(num_choices)\n",
    "            # Iterate over each choice for the current feature\n",
    "            for i in range(num_choices):\n",
    "                # Create a dictionary for the current choice\n",
    "                choice_dict = {}\n",
    "\n",
    "                # Iterate over each key in the feature, excluding 'labels'\n",
    "                for key in feature:\n",
    "                    if key != 'labels' and key != 'id' and key != 'question' and key != 'choices' and key != 'answerKey':\n",
    "                        # Add the data for the current choice to the choice_dict\n",
    "                        choice_dict[key] = feature[key][i]\n",
    "\n",
    "                # Append the dictionary for the current choice to the flattened_features list\n",
    "                flattened_features.append(choice_dict)\n",
    "\n",
    "        # Pad the flattened features\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Reorganize padded data back to their respective feature structures\n",
    "        new_batch = {key: [] for key in batch.keys()}\n",
    "        current_index = 0\n",
    "        for num_choices in num_choices_per_feature:\n",
    "            for key in batch.keys():\n",
    "                new_batch[key].append(batch[key][current_index:current_index + num_choices])\n",
    "            current_index += num_choices\n",
    "\n",
    "        # Convert list of tensors back to tensor for each key\n",
    "        # This needs to handle variable sizes, so we use padding or similar approaches as required\n",
    "        for key in new_batch.keys():\n",
    "            new_batch[key] = torch.nn.utils.rnn.pad_sequence(new_batch[key], batch_first=True)\n",
    "\n",
    "        # Add back labels\n",
    "        new_batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "# features = [{k: v for k, v in tokenized_arc[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "# batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Prepare the input as shown earlier\n",
    "# input_ids = batch['input_ids'].to(model.device)\n",
    "# attention_mask = batch['attention_mask'].to(model.device)\n",
    "# labels = batch['labels'].to(model.device)\n",
    "\n",
    "# # Inference\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "# # Get predictions\n",
    "# logits = outputs.logits\n",
    "# predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# # Evaluate\n",
    "# accuracy = (predictions == labels).float().mean()\n",
    "# print(\"Predictions:\", predictions)\n",
    "# print(\"True Labels:\", labels)\n",
    "# print(\"Accuracy of predictions:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tokenizer.decode(batch[\"input_ids\"][83][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_one(example):\n",
    "#     print(f\"Context: {example['question']}\")\n",
    "#     print(f\"  A - {example['choices']['text'][0]}\")\n",
    "#     print(f\"  B - {example['choices']['text'][1]}\")\n",
    "#     print(f\"  C - {example['choices']['text'][2]}\")\n",
    "#     print(f\"  D - {example['choices']['text'][3]}\")\n",
    "#     print(f\"\\nGround truth: option {[example['answerKey']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_one(arc_dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"fine-tuned-bert-base-uncased-arceasy\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=1.5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    hub_token=\"\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_arc[\"train\"],\n",
    "    eval_dataset=tokenized_arc[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(tokenized_arc[\"test\"])\n",
    "print(test_results)\n",
    "\n",
    "# Save the model\n",
    "#trainer.save_model(\"./arc-trained-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_rlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
